# ğŸª„ GCP Multi-Modal RAG with Vertex AI + AstraDB (Cassandra) + LangChain

A reference implementation that shows how to wire up **Google Vertex AIâ€™s Gemini model**, **DataStax AstraDB (serverless Cassandra-with-vectors)**, and **LangChain** to build a **production-grade, multi-modal Retrieval-Augmented Generation (RAG) service**â€”able to reason over both **text *and* images** at enterprise scale.

---

## âœ¨ Key Capabilities

| Capability | What It Does |
|------------|--------------|
| **Vertex AI Gemini 1.0 Pro / Flash** | Large-context LLM that supports streaming, text-to-text, and image-to-text prompts. |
| **AstraDB Vector Store** | Serverless Cassandra table that stores â†’ retrieves vector embeddings (up to 8Â K dims). |
| **LangChain Orchestration** | Chains, agents, and prompt-templates that glue the LLM + vector store into a unified RAG workflow. |
| **Multi-Modal Support** | Generates image embeddings (using Vertex AI multimodal embeddings) and stores them alongside text chunks. |
| **Streaming & Tuning Hooks** | Demonstrates how to stream responses and tweak generation parameters (temperature, topâ€‘p, etc.). |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     text / image      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   embed + store   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User / UI â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  LangChain    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  AstraDB      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   query + context     â”‚  (chains +   â”‚                   â”‚  (vectors)    â”‚
       â–²                             â”‚    agents)   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚
       â”‚            JSON answer      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   nearestâ€‘N      â”‚              â”‚
       â”‚                                                   vectors     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                                               â–²
       â”‚                         prompt + retrieved docs               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Vertex AI Gemini  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Prerequisites

| Requirement | Notes |
|-------------|-------|
| **PythonÂ 3.10+** | Tested on 3.10Â &Â 3.11 |
| **GCP project with VertexÂ AI enabled** | Billing must be on & you need access to the *GeminiÂ 1.0Â Pro* and *MultimodalÂ Embeddings* models. |
| **DataStax AstraDB instance** | Create a freeâ€‘tier database & generate an application token. |
| **Serviceâ€‘account JSON key** | Recommended for nonâ€‘Colab environments. |

---

## ğŸ“¦ Installation

```bash
# 1. Clone the repo
git clone https://github.com/<your-org>/gcp-multimodal-rag-vertex-ai-astradb.git
cd gcp-multimodal-rag-vertex-ai-astradb

# 2. Create & activate a virtualenv
python -m venv .venv
source .venv/bin/activate

# 3. Install deps
pip install --upgrade google-cloud-aiplatform                        ragstack-ai                        langchain                        langchain-google-vertexai==2.0.5                        cassandra-driver                        python-dotenv
```

---

## ğŸ” Environment Variables

Create a `.env` file or export the vars in your shell:

```dotenv
# GCP
GCP_PROJECT_ID=your-gcp-project
LOCATION=us-central1           # or europe-west4, asia-southeast1, â€¦

# Vertex AI models
VERTEX_TEXT_MODEL=gemini-1.0-pro
VERTEX_IMAGE_EMBED_MODEL=multimodalembedding@001

# AstraDB
ASTRA_DB_API_ENDPOINT=https://<db-id>-<region>.apps.astra.datastax.com
ASTRA_DB_APPLICATION_TOKEN=AstraCS:â€¦      # NEVER hardâ€‘code in code!
ASTRA_NAMESPACE=vertex_rag_demo
ASTRA_COLLECTION=multimodal_docs
```

> **Headsâ€‘up:**  
> The sample notebook in the repo contains placeholder tokens that must be replaced with *your* secrets or, better, loaded from environment variables.

---

## ğŸš€ Running the Demo

```bash
python gcp_multimodal_rag_using_vertex_ai_astradb-langchain.py
```

The script will:

1. **Authenticate** to GCP (serviceâ€‘account or `gcloud auth login`) and initialise VertexÂ AI.  
2. **Connect** to AstraDB and create the vector collection if it doesnâ€™t exist.  
3. **Ingest** a sample set of images + captions into the vector store (both text & image embeddings).  
4. **Build** a LangChain `RetrievalQA` chain that:  
   * embeds the incoming (text or image) query  
   * fetches the topâ€‘`k` nearest neighbours from AstraDB  
   * composes a prompt with the retrieved context  
   * calls Gemini in **streaming** mode for lowâ€‘latency partial results  
5. **Print** the modelâ€™s answer and metadata (source docs, generation time, token counts).

---

## ğŸ§‘â€ğŸ’» Quickâ€‘Start Example

```python
from chains import multimodal_rag_chain

question = "ğŸ“¸Â Â What landmark is in this picture and why is it architecturally significant?"
answer = multimodal_rag_chain(
    query_image_path="assets/golden_gate.jpg",
    query_text=None,
    stream=True,
)

print("\n\nğŸ¤–", answer)
```

---

## ğŸ› ï¸ Customization Tips

| What to Change | How |
|----------------|-----|
| **Model variant** | Swap `gemini-1.0-pro` for `gemini-1.0-flash` in `VERTEX_TEXT_MODEL`. |
| **Temperature / Topâ€‘p** | Edit the `GenerationConfig` block. |
| **Vector distance** | Adjust `similarity_metric="cosine"` vs `"dot_product"` in the AstraDB collection. |
| **Hybrid Search** | Combine vector + keyword search by adding Astraâ€™s `filter` clause in the retriever. |
| **Chunking strategy** | Replace the default `RecursiveCharacterTextSplitter` in `ingest.py`. |

---

## ğŸ“‚ Repo Layout

```
.
â”œâ”€ ingest.py                # oneâ€‘off loader to push docs/images into AstraDB
â”œâ”€ gcp_multimodal_rag_using_vertex_ai_astradb-langchain.py  # main demo script
â”œâ”€ chains.py                # reusable LangChain chains / prompts
â”œâ”€ requirements.txt
â””â”€ README.md                # â† you are here
```

---

## âœ… Roadmap

- [ ] Add **Cloud Run** deployment guide  
- [ ] Example **Dockerfile** with gcloud + cassandra-driver baked in  
- [ ] **FastAPI** wrapper for easy REST / gRPC serving  
- [ ] Optional **Cloud Storage** bucket for raw image assets  
- [ ] **CI/CD** GitHub Actions workflow with unit tests

---

## ğŸ¤ Contributing

PRs are welcome! Please open an issue first to discuss major changes.  
Make sure to **remove or redact any secrets** before committing.

---

## ğŸ“ License

[MIT](LICENSE)

---

### â­ If you find this useful, give the repo a star and drop me a note on LinkedIn!
